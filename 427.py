# -*- coding: utf-8 -*-
"""427.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1trZC6zcn7c9BX9aGYBNK-HcN7SS3KOtA
"""



import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
data = pd.read_csv('/content/pdb_data_seq[1].csv')
data2=pd.read_csv('/content/pdb_data_no_dups[1].csv')
#print(data.head())
description = data.describe()
#print(description)

protein_char = data2[data2.macromoleculeType == 'Protein']
protein_seq =data[data.macromoleculeType == 'Protein']
protein_seq.head()
protein_seq.head()

protein_seq.describe(include="all")
protein_seq.describe(include="all")

# Select  some variables to join
protein_char = protein_char[['structureId','classification','residueCount', 'resolution',
       'structureMolecularWeight','crystallizationTempK', 'densityMatthews', 'densityPercentSol', 'phValue']]
protein_seq = protein_seq[['structureId','sequence']]
protein_seq.head()
residue_count = protein_char['residueCount']
molecular_weight = protein_char['structureMolecularWeight']

# Creating the scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(residue_count, molecular_weight, alpha=0.5)
plt.title('Relationship between Residue Count and Structure Molecular Weight')
plt.xlabel('Residue Count')
plt.ylabel('Structure Molecular Weight')
plt.grid(True)
plt.show()

protein_char.head()

# Join two datasets on structureId
model_f = protein_char.set_index('structureId').join(protein_seq.set_index('structureId'))
model_f.head()

print('%d is the number of rows in the joined dataset' %model_f.shape[0])

# Check NA counts
model_f.isnull().sum()

# Drop rows with missing values
model_f = model_f.dropna()
print('%d is the number of proteins that have a classification and sequence' %model_f.shape[0])

# Look at classification type counts
counts = model_f.classification.value_counts()
print(counts)

#plot counts
plt.figure()
sns.distplot(counts, hist = False, color = 'purple')
plt.title('Count Distribution for Family Types')
plt.ylabel('% of records')
plt.show()

# Get classification types where counts are over 1000
types = np.asarray(counts[(counts > 1000)].index)
print(len(types))
# Filter dataset's records for classification types > 1000
data = model_f[model_f.classification.isin(types)]
data = data.drop_duplicates(subset=["classification","sequence"])  # leaving more rows results in duplciates / index related?

print(types)
print('%d is the number of records in the final filtered dataset' %data.shape[0])

data = data.drop_duplicates(subset=["classification","sequence"])
data.shape

def char_grams(text,n=6,jump_size=2):
    return [text[i:i+n] for i in range(0,len(text)-n+1,jump_size)]

data["3mers"] = data.sequence.apply(char_grams)

data.tail()

data.to_csv("protein_classification_46k_ngrams.csv.gz",compression="gzip")
print(data)

# Split Data
X_train, X_test,y_train,y_test = train_test_split(data['sequence'], data['classification'], test_size = 0.4, random_state = 27)

# Create a Count Vectorizer to gather the unique elements in sequence
vect = CountVectorizer(analyzer = 'char_wb', ngram_range = (4,4))

# Fit and Transform CountVectorizer
vect.fit(X_train)
vect.fit(X_test)
X_train_df = vect.transform(X_train)
X_test_df = vect.transform(X_test)

#ML MODELS

# Make a prediction dictionary to store accuracys
prediction = dict()

from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import confusion_matrix
rf_model = RandomForestClassifier()
rf_model.fit(X_train_df, y_train)

rf_pred = rf_model.predict(X_test_df)

prediction["RandomForest"] = accuracy_score(rf_pred, y_test)

# Print the accuracy
print(prediction['RandomForest'])


# Calculate the confusion matrix
conf_matrix = confusion_matrix(y_test, rf_pred)

# Print the confusion matrix
print("Confusion Matrix:")
print(conf_matrix)



import seaborn as sns
import matplotlib.pyplot as plt

# Plotting the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()



# Adaboost
from sklearn.ensemble import AdaBoostClassifier
model = AdaBoostClassifier()
model.fit(X_train_df,y_train)
ADA_pred = model.predict(X_test_df)
prediction["Adaboost"] = accuracy_score(ADA_pred , y_test)
print(prediction["Adaboost"])


# Calculate the confusion matrix
conf_matrix2 = confusion_matrix(y_test, ADA_pred)

# Print the confusion matrix
print("Confusion Matrix:")
print(conf_matrix2)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix2, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

from sklearn.svm import SVC

# Create and train the SVM model
svm_model = SVC()  # You can specify parameters here if needed
svm_model.fit(X_train_df, y_train)

# Make predictions
svm_pred = svm_model.predict(X_test_df)

# Calculate accuracy and store the prediction
prediction["SVM"] = accuracy_score(svm_pred, y_test)

# Print the accuracy
print(prediction['SVM'])

